<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Web Audio Player</title>
    <style>
      canvas {
        border: 1px solid #000;
      }
    </style>
  </head>

  <body>
    <input type="file" id="fileInput" accept="audio/*" />
    <br />
    <canvas id="waveform" width="800" height="100"></canvas>
    <br />
    <button id="playButton">Play</button>
    <input id="loopCheckbox" name="loop" type="checkbox" />
    <label for="loopCheckbox">Loop</label>
    <input id="polyCheckbox" name="poly" type="checkbox" />
    <label for="polyCheckbox">Poly</label>
    <input id="drawCheckbox" name="draw" type="checkbox" />
    <label for="drawCheckbox">Draw</label>

    <script>
      window.onload = () => {
        const fileInput = document.getElementById("fileInput");
        const waveformCanvas = document.getElementById("waveform");
        const playButton = document.getElementById("playButton");
        const loopCheckbox = document.getElementById("loopCheckbox");
        const polyCheckbox = document.getElementById("polyCheckbox");
        const drawCheckbox = document.getElementById("drawCheckbox");
        const ctx = waveformCanvas.getContext("2d");
        let audioContext = new AudioContext();
        let audioBuffer;
        let animationId;
        let currentTime = 0;
        let sources = [];
        let isMouseDown = false;

        const bufferLength = audioContext.sampleRate * 1; // for 1 second of audio
        audioBuffer = audioContext.createBuffer(
          2,
          bufferLength,
          audioContext.sampleRate
        );

        fileInput.addEventListener("change", async (event) => {
          const file = event.target.files[0];
          const arrayBuffer = await readFile(file);
          audioBuffer = await new AudioContext().decodeAudioData(arrayBuffer);
          drawWaveform();
        });

        const readFile = (file) => {
          return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => resolve(reader.result);
            reader.onerror = reject;
            reader.readAsArrayBuffer(file);
          });
        };

        const drawWaveform = () => {
          const data = audioBuffer.getChannelData(0);
          const step = Math.ceil(data.length / waveformCanvas.width);
          const amp = waveformCanvas.height / 2;
          ctx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
          ctx.beginPath();
          for (let i = 0; i < waveformCanvas.width; i++) {
            const min = 1 + step * i;
            const max = 1 + step * i + step;
            let minVal = 0;
            let maxVal = 0;
            for (let j = min; j < max; j++) {
              if (data[j] < minVal) minVal = data[j];
              if (data[j] > maxVal) maxVal = data[j];
            }
            const x = i;
            const y = (1 + minVal) * amp;
            const height = Math.max(1, (maxVal - minVal) * amp);
            ctx.strokeStyle = "#000";
            ctx.lineWidth = 1;
            ctx.moveTo(x, y);
            ctx.lineTo(x, y + height);
          }
          ctx.stroke();
        };

        function resetPlayback(x) {
          if (!audioBuffer) return;
          if (sources.length > 0 && !polyCheckbox.checked) {
            for (var source of sources) source.stop(0);
          }
          var source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          if (x < 0) x = 0;
          currentTime = (x * audioBuffer.duration) / waveformCanvas.width;
          source.loop = loopCheckbox.checked;
          source.start(0, currentTime);
          sources.push(source);
          cancelAnimationFrame(animationId);
          drawPlayhead();
        }

        playButton.addEventListener("click", () => {
          if (!audioBuffer) return;
          if (sources.length > 0 && !polyCheckbox.checked) {
            for (var source of sources) source.stop(0);
          }
          var source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          currentTime = 0; // Reset current time
          source.loop = loopCheckbox.checked;
          source.start(currentTime, 0); // Start from the beginning
          sources.push(source);
          cancelAnimationFrame(animationId); // Stop previous animation frame
          drawPlayhead(); // Start drawing playhead from the beginning
        });

        const drawPlayhead = () => {
          if (!audioContext || sources.length == 0) return;

          const loopCheckbox = document.getElementById("loopCheckbox");
          let playbackTime = audioContext.currentTime + currentTime;
          var source = sources.at(-1);
          if (source.loop) {
            playbackTime = playbackTime % audioBuffer.duration;
          }
          const position =
            (playbackTime * waveformCanvas.width) / audioBuffer.duration;

          ctx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
          drawWaveform();
          ctx.fillStyle = "red";
          ctx.fillRect(position, 0, 1, waveformCanvas.height);

          animationId = requestAnimationFrame(drawPlayhead);
        };

        waveformCanvas.addEventListener("click", (event) => {
          if (!audioBuffer) return;
          if (!drawCheckbox.checked) resetPlayback(event.x);
        });

        waveformCanvas.addEventListener("mousedown", (event) => {
          if (drawCheckbox.checked) startDrawing(event);
          isMouseDown = true;
        });

        waveformCanvas.addEventListener("mousemove", (event) => {
          if (isMouseDown && drawCheckbox.checked) {
            continueDrawing(event);
          } else if (isMouseDown) resetPlayback(event.x);
        });

        window.addEventListener("mouseup", () => {
          if (isMouseDown && drawCheckbox.checked) {
            stopDrawing();
          } else if (isMouseDown) isMouseDown = false;
        });

        function pixToSamp(x, rect, canvasWidth) {
          x -= rect.left;
          const samplesPerPixel = audioBuffer.length / canvasWidth;
          return Math.floor(x * samplesPerPixel);
        }

        function startDrawing(event) {
          // Initialize drawing process here
          if (!audioBuffer) return;
          // Assuming mono for simplicity
          const channelData = audioBuffer.getChannelData(0);
          const rect = waveformCanvas.getBoundingClientRect();
          const canvasWidth = waveformCanvas.width;
          const canvasHeight = waveformCanvas.height;
          const sampleIndex = pixToSamp(event.x, rect, canvasWidth);
          if (sampleIndex < 0) sampleIndex = 0;
          else if (sampleIndex >= audioBuffer.length)
            sampleIndex = audioBuffer.length - 1;

          // Placeholder: Display sample index and value for debugging
          console.log(`Start drawing at sample ${sampleIndex}`);
        }

        function continueDrawing(event) {
          // Initialize drawing process here
          if (!audioBuffer) return;
          // Assuming mono for simplicity
          const channelData = audioBuffer.getChannelData(0);
          const rect = waveformCanvas.getBoundingClientRect();
          const canvasWidth = waveformCanvas.width;
          const canvasHeight = waveformCanvas.height;
          var sampleIndex = pixToSamp(event.x, rect, canvasWidth);
          if (sampleIndex < 0) sampleIndex = 0;
          else if (sampleIndex >= audioBuffer.length)
            sampleIndex = audioBuffer.length - 1;

          // Placeholder: Display sample index and value for debugging
          console.log(`Drawing at sample ${sampleIndex}`);
        }

        function stopDrawing() {
          // Finalize drawing process here
        }
      };
    </script>
  </body>
</html>
