<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Web Audio Player</title>
    <style>
      canvas {
        border: 1px solid #000;
      }
    </style>
  </head>

  <body>
    <input type="file" id="fileInput" accept="audio/*" />
    <br />
    <canvas id="waveform" width="800" height="100"></canvas>
    <br />
    <button id="playButton">Play</button>
    <input id="loopCheckbox" name="loop" type="checkbox" />
    <label for="loopCheckbox">Loop</label>
    <input id="polyCheckbox" name="poly" type="checkbox" />
    <label for="polyCheckbox">Poly</label>
    <input id="drawCheckbox" name="draw" type="checkbox" />
    <label for="drawCheckbox">Draw</label>
    <br />
    <br />
    <label>Voices: </label>
    <input id="voicesNumbox" type="number" min="1" max="128" value="8" />

    <script>
      const colors = Array.from(
        { length: 128 },
        (_, i) => `hsl(${(i / 128) * 360}, 100%, 50%)`
      );
      window.onload = () => {
        const fileInput = document.getElementById("fileInput");
        const waveformCanvas = document.getElementById("waveform");
        const playButton = document.getElementById("playButton");
        const loopCheckbox = document.getElementById("loopCheckbox");
        const polyCheckbox = document.getElementById("polyCheckbox");
        const drawCheckbox = document.getElementById("drawCheckbox");
        const voicesNumbox = document.getElementById("voicesNumbox");
        const ctx = waveformCanvas.getContext("2d");
        let audioContext = new AudioContext();
        let audioBuffer;
        let animationId;
        let sources = [];
        let isMouseDown = false;
        let colorIndex = 0;
        let isDrawing = false;
        let lastDrawnSampleIndex = null;

        const bufferLength = audioContext.sampleRate * 1; // for 1 second of audio
        audioBuffer = audioContext.createBuffer(
          2,
          bufferLength,
          audioContext.sampleRate
        );

        fileInput.addEventListener("change", async (event) => {
          const file = event.target.files[0];
          const arrayBuffer = await readFile(file);
          audioBuffer = await new AudioContext().decodeAudioData(arrayBuffer);
          drawWaveform();
        });

        const readFile = (file) => {
          return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => resolve(reader.result);
            reader.onerror = reject;
            reader.readAsArrayBuffer(file);
          });
        };

        const drawWaveform = () => {
          const data = audioBuffer.getChannelData(0);
          const step = Math.ceil(data.length / waveformCanvas.width);
          const amp = waveformCanvas.height / 2;
          ctx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
          ctx.beginPath();
          for (let i = 0; i < waveformCanvas.width; i++) {
            const min = 1 + step * i;
            const max = 1 + step * i + step;
            let minVal = 0;
            let maxVal = 0;
            for (let j = min; j < max; j++) {
              if (data[j] < minVal) minVal = data[j];
              if (data[j] > maxVal) maxVal = data[j];
            }
            const x = i;
            const y = (1 + minVal) * amp;
            const height = Math.max(1, (maxVal - minVal) * amp);
            ctx.strokeStyle = "#000";
            ctx.lineWidth = 1;
            ctx.moveTo(x, y);
            ctx.lineTo(x, y + height);
          }
          ctx.stroke();
        };

        playButton.addEventListener("click", () => {
          if (!audioBuffer) return;
          var source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          source.loop = loopCheckbox.checked;
          if (sources.length > 0 && !polyCheckbox.checked) {
            for (var src of sources) src.source.stop();
            sources = sources.slice(0, 1);
            sources[0].source = source;
            sources[0].startTime = audioContext.currentTime;
            sources[0].startOffset = 0;
          } else {
            while (sources.length > Number(voicesNumbox.value)) {
              sources[0].source.stop();
              sources = sources.slice(1, voicesNumbox.value);
            }
            sources.push({
              source: source,
              startTime: audioContext.currentTime,
              startOffset: 0,
              color: colors[colorIndex++ % colors.length],
            });
          }
          sources.at(-1).source.start();
          cancelAnimationFrame(animationId);
          drawPlayhead();
        });

        voicesNumbox.addEventListener("change", () => {
          while (sources.length > voicesNumbox.value) {
            sources[0].source.stop();
            sources = sources.slice(1);
          }
        });

        function resetPlayback(x) {
          if (!audioBuffer) return;
          var source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          if (x < 0) x = 0;
          else if (x > waveformCanvas.width) x = waveformCanvas.width - 1;
          var startOffset = (x * audioBuffer.duration) / waveformCanvas.width;
          source.loop = loopCheckbox.checked;
          if (sources.length > 0 && !polyCheckbox.checked) {
            for (var src of sources) src.source.stop();
            sources = sources.slice(0, 1);
            sources[0].source = source;
            sources[0].startTime = audioContext.currentTime;
            sources[0].startOffset = startOffset;
          } else {
            while (sources.length > Number(voicesNumbox.value)) {
              sources[0].source.stop();
              sources = sources.slice(1);
            }
            sources.push({
              source: source,
              startTime: audioContext.currentTime,
              startOffset: startOffset,
              color: colors[colorIndex++ % colors.length],
            });
          }
          sources.at(-1).source.start(0, startOffset);
          cancelAnimationFrame(animationId);
          drawPlayhead();
        }

        const drawPlayhead = () => {
          if (!audioContext || sources.length === 0) return;

          ctx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);
          drawWaveform();

          sources.forEach((src) => {
            if (src == null) pass;
            let playbackTime =
              audioContext.currentTime - src.startTime + src.startOffset;
            if (src.source.loop) {
              playbackTime = playbackTime % audioBuffer.duration;
            }
            const position =
              (playbackTime * waveformCanvas.width) / audioBuffer.duration;
            ctx.fillStyle = src.color;
            ctx.fillRect(position, 0, 1, waveformCanvas.height);
          });

          animationId = requestAnimationFrame(drawPlayhead);
        };

        waveformCanvas.addEventListener("click", (event) => {
          if (!audioBuffer) return;
          if (!drawCheckbox.checked && !isDrawing) resetPlayback(event.x);
        });

        waveformCanvas.addEventListener("mousedown", (event) => {
          if (drawCheckbox.checked) {
            isDrawing = true;
            drawOnWaveform(event);
          }
          isMouseDown = true;
        });

        waveformCanvas.addEventListener("mousemove", (event) => {
          if (isDrawing) {
            drawOnWaveform(event);
          } else if (isMouseDown) resetPlayback(event.x);
        });

        window.addEventListener("mouseup", () => {
          if (isDrawing) {
            isDrawing = false;
            lastDrawnSampleIndex = null;
          }
          isMouseDown = false;
        });

        window.addEventListener("keydown", (event) => {
          let val = Number(voicesNumbox.value);
          if (event.key == "e") voicesNumbox.value = val + 1;
          else if (event.key == "q")
            voicesNumbox.value = val > 1 ? val - 1 : val;
          while (sources.length > Number(voicesNumbox.value)) {
            sources[0].source.stop();
            sources = sources.slice(1);
          }
        });

        function pixToSamp(x, rect, canvasWidth) {
          x -= rect.left;
          const samplesPerPixel = audioBuffer.length / canvasWidth;
          return Math.floor(x * samplesPerPixel);
        }

        function drawOnWaveform(event) {
          const rect = waveformCanvas.getBoundingClientRect();
          const x = event.clientX - rect.left;
          const y = event.clientY - rect.top;
          const canvasWidth = waveformCanvas.width;
          const canvasHeight = waveformCanvas.height;
          const sampleIndex = pixToSamp(event.x, rect, canvasWidth);
          if (sampleIndex === lastDrawnSampleIndex) return;
          lastDrawnSampleIndex = sampleIndex;
          const amplitude = -1 * (1 - (y / canvasHeight) * 2);
          // Assuming mono for simplicity. For stereo, you'd update both channels or a specific one.
          let channels = [];
          channels.push(audioBuffer.getChannelData(0));
          channels.push(audioBuffer.getChannelData(1));
          for (let channel of channels) {
            channel[sampleIndex] = amplitude;
          }
          drawWaveform();
        }
      };
    </script>
  </body>
</html>
